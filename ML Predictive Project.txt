Six Steps to ML predictive modelling project:

1. Define Problem:
2. Analyze Data:  descriptive statistics and visualization to better 
3. Prepare Data:  data transforms in order to better expose the structure of the prediction problem to modeling algorithms
4. Evaluate Algorithms: evaluate a number of standard algorithms on the data and select the top few 
5. Improve Results: Use algorithm tuning and ensemble methods 
6. Present Results: Finalize the model, make predictions and present results

Lessons/Things to-do List:

 Lesson 1: Python Ecosystem for Machine Learning.
 Lesson 2: Python and SciPy Crash Course.
 Lesson 3: Load Datasets from CSV.

 Lesson 4: Understand Data With Descriptive Statistics. (Analyze Data)
 Lesson 5: Understand Data With Visualization. (Analyze Data)

 Lesson 6: Pre-Process Data. (Prepare Data)
 Lesson 7: Feature Selection. (Prepare Data)

 Lesson 8: Resampling Methods. (Evaluate Algorithms)
 Lesson 9: Algorithm Evaluation Metrics. (Evaluate Algorithms)
 Lesson 10: Spot-Check Classification Algorithms. (Evaluate Algorithms)
 Lesson 11: Spot-Check Regression Algorithms. (Evaluate Algorithms)
 Lesson 12: Model Selection. (Evaluate Algorithms)
 Lesson 13: Pipelines. (Evaluate Algorithms)

 Lesson 14: Ensemble Methods. (Improve Results)
 Lesson 15: Algorithm Parameter Tuning. (Improve Results)

 Lesson 16: Model Finalization. (Present Results)


***With SciPy***

 NumPy: A foundation for SciPy that allows you to efficiently work with data in arrays.
 Matplotlib: Allows you to create 2D charts and plots from data.
 Pandas: Tools and data structures to organize and analyze your data.

***Descriptive_Stat****Recipes***

1. Take a peek at your raw data.
2. Review the dimensions of your dataset - "the curse of dimensionality"
3. Review the data types of attributes in your data.
4. Summarize the distribution of instances across classes in your dataset.
5. Summarize your data using descriptive statistics.
6. Understand the relationships in your data using correlations.
7. Review the skew of the distributions of each attribute.


***Visualization Data****Univariate Plots****
 Histograms.
 Density Plots.
 Box and Whisker Plots

***Multivariate Plots***
 Correlation Matrix Plot
 Scatter Plot Matrix


***Prepare_Data***
pre-processing methods:
 Fit and Multiple Transform.
 Combined Fit-And-Transform.
***Rescale Data + Standardize Data + Normalize Data + Binarize Data***


***Feature_Selection***   Reduces Overfitting  Improves Accuracy  Reduces Training Time
 Univariate Selection: chi-squared
 Recursive Feature Elimination(RFE): logi regression
 Principal Component Analysis (or PCA or Data Reduction Technique): choose principal componenets 
 Feature Importance: Random Forest and Extra Trees Classifier to estimate the importance of features


***Performance_of_Machine_Learning_Algorithms_with_Resampling***
 Train and Test Sets: 
 k-fold Cross Validation (Best results, use whe in doubt)
 Leave One Out Cross Validation.(Lot of Variance in results)
 Repeated Random Test-Train Splits (Shuffle Split Cross Validation)


***ML_Algo_Performance_Metrics***

**Classification_Problems**
 Classification Accuracy (when an equal number of observations in each class)
 Logarithmic Loss(LogLoss: probabilities of memebership of given class, on logistic regression, of course!)
 Area Under ROC Curve or AUC(perfect for Binary Classification Problems, Trade-off between sensitivity and specificity)
 Confusion Matrix
 Classification Report

**Regressiom_Problems**
 Mean Absolute Error
 Mean Squared Error
 R2